[{"content":"UDP and TCP two main protocols in the Transport Layer of the OSI and TCP/IP models. Both protocols help applications to communicate with each other, however, they are different mainly in terms of speed, reliability and use cases. We will explore the basic ideas behind each protocol and their use cases.\nUser Datagram Protocol The User Datagram Protocol (UDP) is an efficient communication protocol which allows fast transmission of data packet at the cost of reliability. The protocol works by sending packets directly to the target computer without setting up the connection. It\u0026rsquo;s worth to note that the UDP protocol does not guarantee packet delivery, and the ordering of the packets.\nUDP packets are referred as datagrams.\nTransmission Control Protocol The Transmission Control Protocol requires two computers establishing a connection before sending packets to each other. This process is called a \u0026ldquo;handshake\u0026rdquo;. After the connection has been established, the two computers can communicate with each other by sending packets. TCP will handle resending lost packets or rearranging packets which received out of order.\nThe 3-way handshaking process\nStep 1: (SYN) The sender will send a segment SYN to inform the receiver about the incoming connection and with what sequence number Step 2: (SYN + ACK) The receiver once received the message from sender will respond with a packet containing SYN + ACK flags. The ACK is the acknowledge flag, telling to the sender that it has received the SYN packet. The SYN indicates the starting sequence number that it wants to start with. Step 3: (ACK) The sender acknowledge and response to the receiver. The reliable connection is then established. SYN (Synchronise Sequence Number) tells what the sequence number should the data start with, which will ensure correct data transmission and packets reordering if needed.\nFor example,\nThe sender starting sequence is #1000 The receiver starting sequence is #5000 Once both sides know about SYN, then data can flow safely in both directions. If neither two does not specify the starting sequence, then packets can not be reordered and transmitted correctly. Figure: TCP vs UDP communication overview (Cloudflare).\nUse cases UDP\nReal-time traffic where low latency matters more than perfect delivery (voice, video, gaming) For instance, it\u0026rsquo;s generally prefer to have a slightly blurry video than high-resolution video but heavily delayed Lightweight request/response (DNS lookups) TCP\nReliable, ordered delivery for complete data transfer (file transfer, web browsing) Interactive sessions that need in-order text (SSH, chat/messaging) References https://www.cloudflare.com/en-gb/learning/ddos/glossary/user-datagram-protocol-udp/ https://www.geeksforgeeks.org/computer-networks/tcp-3-way-handshake-process/ ","permalink":"https://davidnguyen58.github.io/An_Blog/posts/blog2_udp_tcp/","summary":"\u003cp\u003eUDP and TCP two main protocols in the Transport Layer of the OSI and TCP/IP models. Both protocols help applications to communicate with each other, however, they are different mainly in terms of speed, reliability and use cases. We will explore the basic ideas behind each protocol and their use cases.\u003c/p\u003e\n\u003ch2 id=\"user-datagram-protocol\"\u003eUser Datagram Protocol\u003c/h2\u003e\n\u003cp\u003eThe User Datagram Protocol (UDP) is an efficient communication protocol which allows fast transmission of data packet at the cost of reliability. The protocol works by sending packets directly to the target computer without setting up the connection. It\u0026rsquo;s worth to note that the UDP protocol does not guarantee packet delivery, and the ordering of the packets.\u003c/p\u003e","title":"TCP vs UDP"},{"content":"When I first learnt about Deep Learning, I was always wondering how can these neural networks can perform a wide range of complex tasks. The idea of defining an objective function and then train the neural networks to minimise that seems intuitive to understand about the mechanism but does not justify why it would work. It turns out that when I came across the Universal Approximation Theorem, things get clearer.\nTheorem The Universal Approximation Theorem, in lose terms, tells us that a feedforward network with a linear output layer and at least one hidden layer with any \u0026ldquo;squashing\u0026rdquo; activation function can approximate any continuous function to any desired degree of accuracy. [1]\nThis has given mathematical justifications that large and deep neural networks can model complex non-linear data found in the real world.\nHowever, it should be noted that the existence of such neural networks does not guarantee the learning algorithm would be able to learn that function.\nExperiment Let\u0026rsquo;s experiment with a toy example. We will try to construct a simple feedforward neural network to approximate the function:\n$$ f(x)=e^{-x^2} $$\nModel architecture\nLinear → Sigmoid → Hidden (hidden=16) → Linear\nTraining configuration\nSetting Value BATCH_SIZE 32 EPOCHS 200 OPTIMISER ADAM LR 1e-3 The source code could be found in here\nEvaluation After the training, here is the graph to compare between our model approximation and the target function. As we can see, they\u0026rsquo;re very close to each other!\nThe loss over time could be seen below\nThe training and testing loss to a MSE value of 0.000004, which show similarity between two models\nConclusion The experiment shows that even a very simple neural network can approximate a \u0026ldquo;complex\u0026rdquo; continuous function quite well. I hope this post gives you an intuitive sense of the theorem and why neural networks are so powerful. I do not cover the proof here, but there are several interesting proofs available online. I may write about them in a future post. Happy reading!\nReferences [1] Ian Goodfellow, Yoshua Bengio, and Aaron Courville. Deep Learning. MIT Press, 2016. Chapter 6: Deep Feedforward Networks.\n","permalink":"https://davidnguyen58.github.io/An_Blog/posts/blog1_uat/","summary":"\u003cp\u003eWhen I first learnt about Deep Learning, I was always wondering how can these neural networks can perform a wide range of complex tasks. The idea of defining an objective function and then train the neural networks to minimise that seems intuitive to understand about the mechanism but does not justify why it would work. It turns out that when I came across the Universal Approximation Theorem, things get clearer.\u003c/p\u003e","title":"Universal Approximation Theorem"}]